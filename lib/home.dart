import 'dart:async';
import 'dart:convert';
import 'dart:io';
import 'package:camera/camera.dart';
import 'package:flutter/material.dart';
import 'package:flutter_bloc/flutter_bloc.dart';
import 'package:flutter_tts/flutter_tts.dart';
import 'package:http/http.dart' as http;
import 'package:http_parser/http_parser.dart';
import 'package:image_picker/image_picker.dart';
import 'package:nb_utils/nb_utils.dart';
import 'package:permission_handler/permission_handler.dart';
import 'package:speech_to_text/speech_to_text.dart' as stt;
import 'package:vibration/vibration.dart';
import 'cubit/object_cubit.dart';
import 'cubit/object_state.dart';
import 'object_model.dart';

class FeatureCardScreen extends StatefulWidget {
  const FeatureCardScreen({super.key});
  @override
  State<FeatureCardScreen> createState() => _FeatureCardScreenState();
}

class _FeatureCardScreenState extends State<FeatureCardScreen> {
  final List<Map<String, String>> features = [
    {
      'title': 'Scene Detection',
      'endpoint': 'scene-detection',
      'description': 'Analyze a scene and get a description',
      'image': 'assets/virus-search.png',
    },
    {
      'title': 'Object Detection',
      'endpoint': 'detect-objects',
      'description': 'Detect objects in the image',
      'image': 'assets/tracking.png',
    },
    {
      'title': 'Safety Alerts',
      'endpoint': 'safety-alerts',
      'description': 'Identify potential hazards in the scene',
      'image': 'assets/reminder.png',
    },
  ];

  late CameraController _cameraController;
  late List<CameraDescription> _cameras;
  late PageController _pageController;
  late stt.SpeechToText _speech;
  late FlutterTts _flutterTts;

  final ImagePicker _picker = ImagePicker();

  String? selectedEndpoint;
  String _voiceCommand = '';
  String resultText = '';
  String? errorText;

  bool _isCameraInitialized = false;
  bool _isListening = false;
  bool isCapturing = false;
  bool isLoading = false;
  bool _hasSpoken = false;
  bool _isDisposed = false; // Ù…ØªØºÙŠØ± Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù†Ù‡ ØªÙ… Ø§Ù„ØªØ®Ù„Øµ Ù…Ù† Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§

  Timer? _detectionTimer;
  @override
  void initState() {
    super.initState();
    _pageController = PageController();
    _speech = stt.SpeechToText();
    _flutterTts = FlutterTts();

    _initializeCamera(); // ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§

    // Ø§Ù„ØªØ­Ø¯Ø« Ø¨Ø±Ø³Ø§Ù„Ø© Ø§Ù„ØªØ±Ø­ÙŠØ¨ Ø¹Ù†Ø¯ Ø£ÙˆÙ„ ØªØ´ØºÙŠÙ„
    if (!_hasSpoken) {
      _speakWelcomeMessage();
      _hasSpoken = true;
    }
  }

  // ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
  void _initializeCamera() async {
    try {
      // ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
      _cameraController = CameraController(
        _cameras[0], // Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        ResolutionPreset.high,
      );

      await _cameraController.initialize();

      if (!mounted) return; // ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù†Ù‡ Ù„Ø§ ÙŠØ²Ø§Ù„ Ù„Ø¯ÙŠÙ†Ø§ Ø§Ù„ØµÙØ­Ø©
      setState(() {
        _isCameraInitialized = true; // ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ ØªÙ… ØªÙ‡ÙŠØ¦ØªÙ‡Ø§
      });
    } catch (e) {
      // Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªÙ‡ÙŠØ¦Ø©
      print("Camera initialization failed: $e");
    }
  }

  @override
  void dispose() {
    // Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­ Ø¹Ù†Ø¯ Ù…ØºØ§Ø¯Ø±Ø© Ø§Ù„ØµÙØ­Ø©
    _detectionTimer?.cancel();
    _flutterTts.stop();

    if (_cameraController != null) {
      _cameraController.dispose(); // ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„ØªØ®Ù„Øµ Ù…Ù† Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­
    }

    _isDisposed = true; // ØªØ¹ÙŠÙŠÙ† _isDisposed Ø¹Ù„Ù‰ true Ù„Ø¶Ù…Ø§Ù† Ø¹Ø¯Ù… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ø¨Ø¹Ø¯ Ø§Ù„ØªØ®Ù„Øµ Ù…Ù†Ù‡Ø§
    _pageController.dispose();
    super.dispose();
  }

  Future<bool> _requestCameraPermission() async {
    var status = await Permission.camera.status;
    if (!status.isGranted) {
      status = await Permission.camera.request();
    }
    return status.isGranted;
  }

  Future<void> _speakText(String text) async {
    await _flutterTts.setLanguage("en");
    await _flutterTts.setSpeechRate(0.5);
    await _flutterTts.setPitch(1.0);
    await _flutterTts.speak(text);
  }

  Future<void> _speakWelcomeMessage() async {
    await _flutterTts.setLanguage('en');
    await _flutterTts.setSpeechRate(0.5);
    await _flutterTts.setPitch(1.0);
    await _flutterTts.speak(
      "swipe left or right the top section of screen to select a feature, and double-tap to activate it.",
    );
  }

  Future<void> _speakFeatureTitle(int index) async {
    await _flutterTts.stop();
    await _flutterTts.setLanguage('en');
    await _flutterTts.setSpeechRate(0.5);
    await _flutterTts.setPitch(1.0);
    if (index < features.length) {
      String title = features[index]['title'] ?? 'Unknown Feature';
      String description = features[index]['description'] ?? 'No description';
      await _flutterTts.speak("Feature: $title that is  $description ");
    } else {
      await _flutterTts.speak(
        "Feature : Extracted Text that is Read text from image",
      );
    }
  }

  void triggerVibration() async {
    if (await Vibration.hasVibrator() ?? false) {
      Vibration.vibrate(pattern: [0, 500, 300, 500, 300, 500]);
    } else {
      Fluttertoast.showToast(msg: 'Device not support Vibration');
      await _speakText('Device not support Vibration');
    }
  }

  void _startListening() async {
    var status = await Permission.microphone.request();
    if (!status.isGranted) {
      return;
    }

    bool available = await _speech.initialize(
      onStatus: (status) {
        if (status == 'done') {
          setState(() => _isListening = false);
        }
      },
      onError: (error) {
        setState(() => _isListening = false);
      },
    );

    if (available) {
      setState(() => _isListening = true);
      _speech.listen(
        localeId: 'en',
        onResult: (result) {
          if (result.finalResult) {
            _handleVoiceCommand(result.recognizedWords);

            _speech.stop();
            Future.delayed(Duration(milliseconds: 500), () {
              if (mounted) _startListening();
            });
          }
        },
      );
    } else {
      print('Speech recognition not available');
    }
  }

  Future<void> _handleVoiceCommand(String command) async {
    command = command.toLowerCase();
    if (command.trim() == 'open') {
      if (!_isListening) {
        _startListening();
        await _speakText('Listening started');
      } else {
        await _speakText('I am already listening');
      }
      return;
    }
    for (var i = 0; i < features.length; i++) {
      final feature = features[i];
      final title = feature['title']!.toLowerCase();

      if (command.contains(title) ||
          title.split(' ').any((word) => command.contains(word))) {
        // Ù„Ùˆ Ø§Ù„Ù…ÙŠØ²Ø© Ø¯ÙŠ Ø´ØºØ§Ù„Ø© Ø£ØµÙ„Ø§Ù‹
        if (_isCameraInitialized && selectedEndpoint == feature['endpoint']) {
          await _speakText('${feature['title']} is already running');
          return;
        }

        await _speakText('Opening ${feature['title']} feature');

        // ğŸ”„ Ø§Ù„ØªÙ†Ù‚Ù„ Ù„Ù„Ø³Ù„Ø§ÙŠØ¯Ø± Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
        _pageController.animateToPage(
          i,
          duration: const Duration(milliseconds: 500),
          curve: Curves.easeInOut,
        );

        // â–¶ï¸ ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
        await _toggleCamera(feature['endpoint']!);
        return;
      }
    }

    // Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ
    if (command.contains('read') || command.contains('text')) {
      await _speakText('Opening text extraction');
      _pickAndSend('extract-text');
      return;
    }

    // Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
    if (command.contains('camera')) {
      if (_isCameraInitialized) {
        await _speakText('Stopping the camera');
        await _toggleCamera('');
      }
      return;
    }
    if (command.contains('stop record')) {
      if (_isListening) {
        _speech.stop(); // Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹
        await _speakText('Stopped listening');
      }
      return;
    }
    // Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù…Ø± Ø§Ù„ØµÙˆØªÙŠ
    Fluttertoast.showToast(msg: 'Voice command not understood');
    await _speakText('Voice command not understood');
  }


  void _startPeriodicDetection() {
    _detectionTimer?.cancel();
    _detectionTimer = Timer.periodic(const Duration(seconds: 10), (_) {
      if (_isCameraInitialized && selectedEndpoint != null) {
        _captureAndSendFrame();
      }
    });
  }

  Future<void> _toggleCamera(String endpoint) async {
    if (_isCameraInitialized) {
      await _cameraController.dispose(); // ØªÙˆÙ‚Ù Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­
      _detectionTimer?.cancel();
      _isCameraInitialized = false;
      setState(() {
        selectedEndpoint = null;
        resultText = 'Camera stopped.';
        isLoading = false;
      });
      return;
    } else {
      bool hasPermission = await _requestCameraPermission();
      if (!hasPermission) {
        Fluttertoast.showToast(msg: 'Please allow camera permission');
        await _speakText('Please allow camera permission');
        return;
      }

      setState(() {
        selectedEndpoint = endpoint;
        resultText = 'Detecting with: $endpoint';
        isLoading = true;
      });

      await _initCamera(); // Ø¥Ø¹Ø§Ø¯Ø© ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
      _startPeriodicDetection();
    }
  }

  Future<void> _initCamera() async {
    if (_isDisposed) return; // Avoid initializing if widget is disposed

    _cameras = await availableCameras();
    _cameraController = CameraController(
      _cameras.first,
      ResolutionPreset.medium,
    );

    try {
      await _cameraController.initialize();
      if (!mounted || _isDisposed) return;

      setState(() {
        _isCameraInitialized = true;
      });
    } catch (e) {
      if (!_isDisposed) {
        await _speakText('Failed to initialize the camera: $e');
      }
    }
  }

  Future<void> _captureAndSendFrame() async {
    if (isCapturing || selectedEndpoint == null || _isDisposed) return; // Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ ØºÙŠØ± Ù…ÙˆÙ‚ÙˆÙØ©
    if (!_cameraController.value.isInitialized || _isDisposed) return; // ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ù…Ù‡ÙŠØ£Ø© Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­

    isCapturing = true;

    try {
      final XFile file = await _cameraController.takePicture();

      if (_isDisposed || !mounted) return; // ØªØ£ÙƒØ¯ Ù‚Ø¨Ù„ Ø¥Ø¬Ø±Ø§Ø¡ Ø£ÙŠ ØªØ­Ø¯ÙŠØ« Ø¹Ù„Ù‰ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©

      final bytes = await file.readAsBytes();
      final result = await _detectObjects(bytes, selectedEndpoint!);

      if (_isDisposed || !mounted) return;

      if (result != null) {
        setState(() {
          resultText = result['description'] ?? 'No description';
          isLoading = false;
        });

        await _speakText("Image captured and sent for analysis.");

        if (selectedEndpoint == 'safety-alerts') {
          triggerVibration();
        }

        await _speakText(resultText);
      }
    } catch (e) {
      if (!_isDisposed) {
        await _speakText("Error occurred, please try again.");
      }
    } finally {
      isCapturing = false;
    }
  }



  Future<void> _pickAndSend(String endpoint) async {
    bool hasPermission = await _requestCameraPermission();
    if (!hasPermission) {
      Fluttertoast.showToast(msg: 'Please allow camera permission');
      await _speakText('Please allow camera permission');
      return;
    }
    final picked = await _picker.pickImage(source: ImageSource.gallery);
    if (picked != null) {
      final imageFile = File(picked.path);
      context.read<ObjectCubit>().objects(imageFile, endpoint);
      context.read<ObjectCubit>().stream.listen((state) {
        if (state is ObjectSuccess) {
          if (state.prediction.text != null &&
              state.prediction.text!.isNotEmpty) {
            _speakText("Image sent for analysis.");
            _speakText(state.prediction.text!);
          }
        }
      });
    } else {
      await _speakText("No image selected.");
    }
  }

  Future<Map<String, dynamic>?> _detectObjects(
    List<int> imageBytes,
    String endpoint,
  ) async {
    try {
      final String apiUrl = 'http://192.168.100.3:8000/$endpoint';
      final request = http.MultipartRequest('POST', Uri.parse(apiUrl));
      request.files.add(
        http.MultipartFile.fromBytes(
          'file',
          imageBytes,
          filename: 'image.jpg',
          contentType: MediaType('image', 'jpeg'),
        ),
      );

      final streamedResponse = await request.send();
      final response = await http.Response.fromStream(streamedResponse);

      if (response.statusCode == 200) {
        return json.decode(response.body);
      } else {
        return null;
      }
    } catch (e) {
      await _speakText('Error detecting objects: $e');
      return null;
    }
  }



  @override
  Widget build(BuildContext context) {
    return Scaffold(
      appBar: AppBar(
        title: const Text("Smart Vision Features"),
        centerTitle: true,
      ),
      body: Column(
        children: [
          SizedBox(
            height: 200,
            child: PageView.builder(
              controller: _pageController,
              onPageChanged: (index) {
                _speakFeatureTitle(index);
              },
              itemCount: features.length + 1,
              itemBuilder: (context, index) {
                if (index == features.length) {
                  return GestureDetector(
                    onTap: () {
                      context.read<ObjectCubit>().emit(ObjectInitial());
                      setState(() {
                        resultText = '';
                        errorText = null;
                      });
                      _pickAndSend('extract-text');
                    },
                    child: Card(
                      color: const Color(0xFFBDC5DA),
                      margin: const EdgeInsets.all(12),
                      shape: RoundedRectangleBorder(
                        borderRadius: BorderRadius.circular(16),
                      ),
                      child: Padding(
                        padding: const EdgeInsets.all(12),
                        child: Column(
                          crossAxisAlignment: CrossAxisAlignment.center,
                          mainAxisAlignment: MainAxisAlignment.center,
                          children: [
                            const Text(
                              'Text Extraction',
                              style: TextStyle(
                                color: Color(0xFF3B579A),
                                fontSize: 26,
                                fontWeight: FontWeight.bold,
                              ),
                              textAlign: TextAlign.center,
                            ),
                            const SizedBox(height: 1),
                            SizedBox(
                              height: 90,
                              width: double.infinity,
                              child: Image.asset(
                                'assets/file.png',
                                height: 50,
                              ),
                            ),
                            const SizedBox(height: 5),
                            const Text(
                              "Read text from image",
                              style: TextStyle(
                                color: Colors.white,
                                fontSize: 16,
                              ),
                              textAlign: TextAlign.center,
                            ),
                          ],
                        ),
                      ),
                    ),
                  );
                } else {
                  final feature = features[index];
                  return Padding(
                    padding: const EdgeInsets.symmetric(horizontal: 12),
                    child: GestureDetector(
                      onTap: () {
                        context.read<ObjectCubit>().emit(ObjectInitial());
                        setState(() {
                          resultText = '';
                          errorText = null;
                        });
                        _toggleCamera(feature['endpoint']!);
                      },
                      child: Card(
                        elevation:
                        selectedEndpoint == feature['endpoint'] ? 10 : 2,
                        shape: RoundedRectangleBorder(
                          borderRadius: BorderRadius.circular(16),
                        ),
                        color: selectedEndpoint == feature['endpoint']
                            ? const Color(0xFF7D98D6)
                            : const Color(0xFFBDC5DA),
                        child: Padding(
                          padding: const EdgeInsets.all(16),
                          child: Column(
                            crossAxisAlignment: CrossAxisAlignment.center,
                            mainAxisAlignment: MainAxisAlignment.center,
                            children: [
                              // Title of the feature
                              Text(
                                feature['title']!,
                                style: TextStyle(
                                  color: selectedEndpoint == feature['endpoint']
                                      ? Colors.white
                                      : const Color(0xFF3B579A),
                                  fontSize: 26,
                                  fontWeight: FontWeight.bold,
                                ),
                                textAlign: TextAlign.center,
                              ),
                              const SizedBox(height: 1),
                              SizedBox(
                                height: 100,
                                width: double.infinity,
                                child: Image.asset(
                                  feature['image'] != null
                                      ? feature['image']!
                                      : 'assets/default_image.png',
                                  height: 50,
                                ),
                              ),
                              const SizedBox(height: 5),
                              Text(
                                feature['description']!,
                                style: TextStyle(
                                  color: selectedEndpoint == feature['endpoint']
                                      ? Colors.white70
                                      : Colors.white,
                                  fontSize: 18,
                                  fontWeight: FontWeight.bold,
                                ),
                                textAlign: TextAlign.center,
                              ),
                            ],
                          ),
                        ),
                      ),
                    ),
                  );
                }
              },
            ),
          ),
          Expanded(
            child: BlocBuilder<ObjectCubit, ObjectPredictionState>(
              builder: (context, state) {
                // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ù…Ù‡ÙŠØ£Ø© ÙˆÙ„Ù… ÙŠØªÙ… Ø§Ù„ØªØ®Ù„Øµ Ù…Ù†Ù‡Ø§
                if (_isCameraInitialized && !_isDisposed && _cameraController.value.isInitialized)
{
                  return Stack(
                    children: [
                      CameraPreview(_cameraController),
                      if (isLoading)
                        const Center(child: CircularProgressIndicator()),
                      if (resultText.isNotEmpty && !isLoading)
                        Positioned(
                          bottom: 20,
                          left: 20,
                          right: 20,
                          child: Container(
                            padding: const EdgeInsets.all(12),
                            decoration: BoxDecoration(
                              color: Colors.black54,
                              borderRadius: BorderRadius.circular(12),
                            ),
                            child: Text(
                              resultText,
                              style: const TextStyle(
                                color: Colors.white,
                                fontSize: 16,
                              ),
                              textAlign: TextAlign.center,
                            ),
                          ),
                        ),
                    ],
                  );
                } else if (state is ObjectLoading) {
                  // Ø­Ø§Ù„Ø© Ø§Ù„ØªØ­Ù…ÙŠÙ„
                  return const Center(child: CircularProgressIndicator());
                } else if (state is ObjectSuccess) {
                  // Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¬Ø§Ø­ Ù…Ø¹ Ø¹Ø±Ø¶ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø³ØªØ®Ù„ØµØ©
                  return _buildPredictionResult(state.prediction);
                } else if (state is ObjectError) {
                  // ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£
                  return Center(
                    child: Text(
                      state.message,
                      style: const TextStyle(color: Colors.red),
                    ),
                  );
                } else {
                  // Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
                  return const Center(
                    child: Text(
                      "Choose Feature to Start",
                      style: TextStyle(
                        color: Color(0xFF3B579A),
                        fontSize: 22,
                        fontWeight: FontWeight.bold,
                      ),
                    ),
                  );
                }
              },
            ),
          )]),
      floatingActionButton: FloatingActionButton(
        onPressed: _startListening,
        backgroundColor: const Color(0xFFBDC5DA),
        child: Icon(
          _isListening ? Icons.mic : Icons.mic_none,
          color: const Color(0xFF3B579A),
          size: 20,
        ),
      ),
    );
  }
  Widget _buildPredictionResult(ObjectPrediction prediction) {
    return Padding(
      padding: const EdgeInsets.all(16.0),
      child: SingleChildScrollView(
        child: Column(
          crossAxisAlignment: CrossAxisAlignment.center,
          children: [
            if (prediction.text != null)
              SelectableText(
                "Extracted Text:\n${prediction.text!}",
                style: const TextStyle(fontSize: 16, fontWeight: FontWeight.bold),
              ),
            if (prediction.description != null)
              Padding(
                padding: const EdgeInsets.only(top: 8.0),
                child: Text("Description: ${prediction.description!}"),
              ),
            if (prediction.alerts != null && prediction.alerts!.isNotEmpty)
              Padding(
                padding: const EdgeInsets.only(top: 8.0),
                child: Column(
                  crossAxisAlignment: CrossAxisAlignment.start,
                  children: prediction.alerts!
                      .map((alert) => Text("Alert: $alert", style: const TextStyle(color: Colors.red)))
                      .toList(),
                ),
              ),
          ],
        ),
      ),
    );
  }
}
