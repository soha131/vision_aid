===== E:\vision_aid\lib\cubit\object_cubit.dart =====

import 'dart:io';

import 'package:bloc/bloc.dart';
import '../object_model.dart';
import '../service.dart';
import 'object_state.dart';

class ObjectCubit extends Cubit<ObjectPredictionState> {
  ObjectCubit() : super(ObjectInitial());

  Future<void> objects(File file, String endpoint) async {
    try {
      emit(ObjectLoading());

      ObjectPrediction? result = await ApiService().fetchDataFromApi(file, endpoint);

      if (result != null) {
        emit(ObjectSuccess(result));
      } else {
        emit(ObjectError("No data returned from API."));
      }
    } catch (e) {
      emit(ObjectError("Error: $e"));
    }
  }
}
===== E:\vision_aid\lib\cubit\object_state.dart =====
import '../object_model.dart';

abstract class ObjectPredictionState {}

class ObjectInitial extends ObjectPredictionState {}

class ObjectLoading extends ObjectPredictionState {}

class ObjectSuccess extends ObjectPredictionState {
  final ObjectPrediction prediction;
  ObjectSuccess(this.prediction);
}

class ObjectError extends ObjectPredictionState {
  final String message;
  ObjectError(this.message);
}
===== E:\vision_aid\lib\home.dart =====
import 'dart:async';
import 'dart:convert';
import 'dart:io';
import 'package:camera/camera.dart';
import 'package:flutter/material.dart';
import 'package:flutter_bloc/flutter_bloc.dart';
import 'package:flutter_tts/flutter_tts.dart';
import 'package:http/http.dart' as http;
import 'package:http_parser/http_parser.dart';
import 'package:image_picker/image_picker.dart';
import 'package:nb_utils/nb_utils.dart';
import 'package:permission_handler/permission_handler.dart';
import 'package:speech_to_text/speech_to_text.dart' as stt;
import 'package:vibration/vibration.dart';
import 'cubit/object_cubit.dart';
import 'cubit/object_state.dart';
import 'object_model.dart';

class FeatureCardScreen extends StatefulWidget {
  const FeatureCardScreen({super.key});
  @override
  State<FeatureCardScreen> createState() => _FeatureCardScreenState();
}

class _FeatureCardScreenState extends State<FeatureCardScreen> {
  final List<Map<String, String>> features = [
    {
      'title': 'Scene Detection',
      'endpoint': 'scene-detection',
      'description': 'Analyze a scene and get a description',
      'image': 'assets/virus-search.png',
    },
    {
      'title': 'Object Detection',
      'endpoint': 'detect-objects',
      'description': 'Detect objects in the image',
      'image': 'assets/tracking.png',
    },
    {
      'title': 'Safety Alerts',
      'endpoint': 'safety-alerts',
      'description': 'Identify potential hazards in the scene',
      'image': 'assets/reminder.png',
    },
  ];

  late CameraController _cameraController;
  late List<CameraDescription> _cameras;
  late PageController _pageController;
  late stt.SpeechToText _speech;
  late FlutterTts _flutterTts;

  final ImagePicker _picker = ImagePicker();

  String? selectedEndpoint;
  String _voiceCommand = '';
  String resultText = '';
  String? errorText;

  bool _isCameraInitialized = false;
  bool _isListening = false;
  bool isCapturing = false;
  bool isLoading = false;
  bool _hasSpoken = false;
  bool _isDisposed = false; // Ù…ØªØºÙŠØ± Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù†Ù‡ ØªÙ… Ø§Ù„ØªØ®Ù„Øµ Ù…Ù† Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§

  Timer? _detectionTimer;
  @override
  void initState() {
    super.initState();
    _pageController = PageController();
    _speech = stt.SpeechToText();
    _flutterTts = FlutterTts();

    _initializeCamera(); // ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§

    // Ø§Ù„ØªØ­Ø¯Ø« Ø¨Ø±Ø³Ø§Ù„Ø© Ø§Ù„ØªØ±Ø­ÙŠØ¨ Ø¹Ù†Ø¯ Ø£ÙˆÙ„ ØªØ´ØºÙŠÙ„
    if (!_hasSpoken) {
      _speakWelcomeMessage();
      _hasSpoken = true;
    }
  }

  // ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
  void _initializeCamera() async {
    try {
      // ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
      _cameraController = CameraController(
        _cameras[0], // Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        ResolutionPreset.high,
      );

      await _cameraController.initialize();

      if (!mounted) return; // ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù†Ù‡ Ù„Ø§ ÙŠØ²Ø§Ù„ Ù„Ø¯ÙŠÙ†Ø§ Ø§Ù„ØµÙØ­Ø©
      setState(() {
        _isCameraInitialized = true; // ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ ØªÙ… ØªÙ‡ÙŠØ¦ØªÙ‡Ø§
      });
    } catch (e) {
      // Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªÙ‡ÙŠØ¦Ø©
      print("Camera initialization failed: $e");
    }
  }

  @override
  void dispose() {
    // Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­ Ø¹Ù†Ø¯ Ù…ØºØ§Ø¯Ø±Ø© Ø§Ù„ØµÙØ­Ø©
    _detectionTimer?.cancel();
    _flutterTts.stop();

    if (_cameraController != null) {
      _cameraController.dispose(); // ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„ØªØ®Ù„Øµ Ù…Ù† Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­
    }

    _isDisposed = true; // ØªØ¹ÙŠÙŠÙ† _isDisposed Ø¹Ù„Ù‰ true Ù„Ø¶Ù…Ø§Ù† Ø¹Ø¯Ù… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ø¨Ø¹Ø¯ Ø§Ù„ØªØ®Ù„Øµ Ù…Ù†Ù‡Ø§
    _pageController.dispose();
    super.dispose();
  }

  Future<bool> _requestCameraPermission() async {
    var status = await Permission.camera.status;
    if (!status.isGranted) {
      status = await Permission.camera.request();
    }
    return status.isGranted;
  }

  Future<void> _speakText(String text) async {
    await _flutterTts.setLanguage("en");
    await _flutterTts.setSpeechRate(0.5);
    await _flutterTts.setPitch(1.0);
    await _flutterTts.speak(text);
  }

  Future<void> _speakWelcomeMessage() async {
    await _flutterTts.setLanguage('en');
    await _flutterTts.setSpeechRate(0.5);
    await _flutterTts.setPitch(1.0);
    await _flutterTts.speak(
      "swipe left or right the top section of screen to select a feature, and double-tap to activate it.",
    );
  }

  Future<void> _speakFeatureTitle(int index) async {
    await _flutterTts.stop();
    await _flutterTts.setLanguage('en');
    await _flutterTts.setSpeechRate(0.5);
    await _flutterTts.setPitch(1.0);
    if (index < features.length) {
      String title = features[index]['title'] ?? 'Unknown Feature';
      String description = features[index]['description'] ?? 'No description';
      await _flutterTts.speak("Feature: $title that is  $description ");
    } else {
      await _flutterTts.speak(
        "Feature : Extracted Text that is Read text from image",
      );
    }
  }

  void triggerVibration() async {
    if (await Vibration.hasVibrator() ?? false) {
      Vibration.vibrate(pattern: [0, 500, 300, 500, 300, 500]);
    } else {
      Fluttertoast.showToast(msg: 'Device not support Vibration');
      await _speakText('Device not support Vibration');
    }
  }

  void _startListening() async {
    var status = await Permission.microphone.request();
    if (!status.isGranted) {
      return;
    }

    bool available = await _speech.initialize(
      onStatus: (status) {
        if (status == 'done') {
          setState(() => _isListening = false);
        }
      },
      onError: (error) {
        setState(() => _isListening = false);
      },
    );

    if (available) {
      setState(() => _isListening = true);
      _speech.listen(
        localeId: 'en',
        onResult: (result) {
          if (result.finalResult) {
            _handleVoiceCommand(result.recognizedWords);

            _speech.stop();
            Future.delayed(Duration(milliseconds: 500), () {
              if (mounted) _startListening();
            });
          }
        },
      );
    } else {
      print('Speech recognition not available');
    }
  }

  Future<void> _handleVoiceCommand(String command) async {
    command = command.toLowerCase();
    if (command.trim() == 'open') {
      if (!_isListening) {
        _startListening();
        await _speakText('Listening started');
      } else {
        await _speakText('I am already listening');
      }
      return;
    }
    for (var i = 0; i < features.length; i++) {
      final feature = features[i];
      final title = feature['title']!.toLowerCase();

      if (command.contains(title) ||
          title.split(' ').any((word) => command.contains(word))) {
        // Ù„Ùˆ Ø§Ù„Ù…ÙŠØ²Ø© Ø¯ÙŠ Ø´ØºØ§Ù„Ø© Ø£ØµÙ„Ø§Ù‹
        if (_isCameraInitialized && selectedEndpoint == feature['endpoint']) {
          await _speakText('${feature['title']} is already running');
          return;
        }

        await _speakText('Opening ${feature['title']} feature');

        // ðŸ”„ Ø§Ù„ØªÙ†Ù‚Ù„ Ù„Ù„Ø³Ù„Ø§ÙŠØ¯Ø± Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
        _pageController.animateToPage(
          i,
          duration: const Duration(milliseconds: 500),
          curve: Curves.easeInOut,
        );

        // â–¶ï¸ ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
        await _toggleCamera(feature['endpoint']!);
        return;
      }
    }

    // Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ
    if (command.contains('read') || command.contains('text')) {
      await _speakText('Opening text extraction');
      _pickAndSend('extract-text');
      return;
    }

    // Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
    if (command.contains('camera')) {
      if (_isCameraInitialized) {
        await _speakText('Stopping the camera');
        await _toggleCamera('');
      }
      return;
    }
    if (command.contains('stop record')) {
      if (_isListening) {
        _speech.stop(); // Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹
        await _speakText('Stopped listening');
      }
      return;
    }
    // Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù…Ø± Ø§Ù„ØµÙˆØªÙŠ
    Fluttertoast.showToast(msg: 'Voice command not understood');
    await _speakText('Voice command not understood');
  }


  void _startPeriodicDetection() {
    _detectionTimer?.cancel();
    _detectionTimer = Timer.periodic(const Duration(seconds: 10), (_) {
      if (_isCameraInitialized && selectedEndpoint != null) {
        _captureAndSendFrame();
      }
    });
  }

  Future<void> _toggleCamera(String endpoint) async {
    if (_isCameraInitialized) {
      await _cameraController.dispose(); // ØªÙˆÙ‚Ù Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­
      _detectionTimer?.cancel();
      _isCameraInitialized = false;
      setState(() {
        selectedEndpoint = null;
        resultText = 'Camera stopped.';
        isLoading = false;
      });
      return;
    } else {
      bool hasPermission = await _requestCameraPermission();
      if (!hasPermission) {
        Fluttertoast.showToast(msg: 'Please allow camera permission');
        await _speakText('Please allow camera permission');
        return;
      }

      setState(() {
        selectedEndpoint = endpoint;
        resultText = 'Detecting with: $endpoint';
        isLoading = true;
      });

      await _initCamera(); // Ø¥Ø¹Ø§Ø¯Ø© ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
      _startPeriodicDetection();
    }
  }

  Future<void> _initCamera() async {
    if (_isDisposed) return; // Avoid initializing if widget is disposed

    _cameras = await availableCameras();
    _cameraController = CameraController(
      _cameras.first,
      ResolutionPreset.medium,
    );

    try {
      await _cameraController.initialize();
      if (!mounted || _isDisposed) return;

      setState(() {
        _isCameraInitialized = true;
      });
    } catch (e) {
      if (!_isDisposed) {
        await _speakText('Failed to initialize the camera: $e');
      }
    }
  }

  Future<void> _captureAndSendFrame() async {
    if (isCapturing || selectedEndpoint == null || _isDisposed) return; // Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ ØºÙŠØ± Ù…ÙˆÙ‚ÙˆÙØ©
    if (!_cameraController.value.isInitialized || _isDisposed) return; // ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ù…Ù‡ÙŠØ£Ø© Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­

    isCapturing = true;

    try {
      final XFile file = await _cameraController.takePicture();

      if (_isDisposed || !mounted) return; // ØªØ£ÙƒØ¯ Ù‚Ø¨Ù„ Ø¥Ø¬Ø±Ø§Ø¡ Ø£ÙŠ ØªØ­Ø¯ÙŠØ« Ø¹Ù„Ù‰ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©

      final bytes = await file.readAsBytes();
      final result = await _detectObjects(bytes, selectedEndpoint!);

      if (_isDisposed || !mounted) return;

      if (result != null) {
        setState(() {
          resultText = result['description'] ?? 'No description';
          isLoading = false;
        });

        await _speakText("Image captured and sent for analysis.");

        if (selectedEndpoint == 'safety-alerts') {
          triggerVibration();
        }

        await _speakText(resultText);
      }
    } catch (e) {
      if (!_isDisposed) {
        await _speakText("Error occurred, please try again.");
      }
    } finally {
      isCapturing = false;
    }
  }



  Future<void> _pickAndSend(String endpoint) async {
    bool hasPermission = await _requestCameraPermission();
    if (!hasPermission) {
      Fluttertoast.showToast(msg: 'Please allow camera permission');
      await _speakText('Please allow camera permission');
      return;
    }
    final picked = await _picker.pickImage(source: ImageSource.gallery);
    if (picked != null) {
      final imageFile = File(picked.path);
      context.read<ObjectCubit>().objects(imageFile, endpoint);
      context.read<ObjectCubit>().stream.listen((state) {
        if (state is ObjectSuccess) {
          if (state.prediction.text != null &&
              state.prediction.text!.isNotEmpty) {
            _speakText("Image sent for analysis.");
            _speakText(state.prediction.text!);
          }
        }
      });
    } else {
      await _speakText("No image selected.");
    }
  }

  Future<Map<String, dynamic>?> _detectObjects(
    List<int> imageBytes,
    String endpoint,
  ) async {
    try {
      final String apiUrl = 'http://192.168.100.3:8000/$endpoint';
      final request = http.MultipartRequest('POST', Uri.parse(apiUrl));
      request.files.add(
        http.MultipartFile.fromBytes(
          'file',
          imageBytes,
          filename: 'image.jpg',
          contentType: MediaType('image', 'jpeg'),
        ),
      );

      final streamedResponse = await request.send();
      final response = await http.Response.fromStream(streamedResponse);

      if (response.statusCode == 200) {
        return json.decode(response.body);
      } else {
        return null;
      }
    } catch (e) {
      await _speakText('Error detecting objects: $e');
      return null;
    }
  }



  @override
  Widget build(BuildContext context) {
    return Scaffold(
      appBar: AppBar(
        title: const Text("Smart Vision Features"),
        centerTitle: true,
      ),
      body: Column(
        children: [
          SizedBox(
            height: 200,
            child: PageView.builder(
              controller: _pageController,
              onPageChanged: (index) {
                _speakFeatureTitle(index);
              },
              itemCount: features.length + 1,
              itemBuilder: (context, index) {
                if (index == features.length) {
                  return GestureDetector(
                    onTap: () {
                      context.read<ObjectCubit>().emit(ObjectInitial());
                      setState(() {
                        resultText = '';
                        errorText = null;
                      });
                      _pickAndSend('extract-text');
                    },
                    child: Card(
                      color: const Color(0xFFBDC5DA),
                      margin: const EdgeInsets.all(12),
                      shape: RoundedRectangleBorder(
                        borderRadius: BorderRadius.circular(16),
                      ),
                      child: Padding(
                        padding: const EdgeInsets.all(12),
                        child: Column(
                          crossAxisAlignment: CrossAxisAlignment.center,
                          mainAxisAlignment: MainAxisAlignment.center,
                          children: [
                            const Text(
                              'Text Extraction',
                              style: TextStyle(
                                color: Color(0xFF3B579A),
                                fontSize: 26,
                                fontWeight: FontWeight.bold,
                              ),
                              textAlign: TextAlign.center,
                            ),
                            const SizedBox(height: 1),
                            SizedBox(
                              height: 90,
                              width: double.infinity,
                              child: Image.asset(
                                'assets/file.png',
                                height: 50,
                              ),
                            ),
                            const SizedBox(height: 5),
                            const Text(
                              "Read text from image",
                              style: TextStyle(
                                color: Colors.white,
                                fontSize: 16,
                              ),
                              textAlign: TextAlign.center,
                            ),
                          ],
                        ),
                      ),
                    ),
                  );
                } else {
                  final feature = features[index];
                  return Padding(
                    padding: const EdgeInsets.symmetric(horizontal: 12),
                    child: GestureDetector(
                      onTap: () {
                        context.read<ObjectCubit>().emit(ObjectInitial());
                        setState(() {
                          resultText = '';
                          errorText = null;
                        });
                        _toggleCamera(feature['endpoint']!);
                      },
                      child: Card(
                        elevation:
                        selectedEndpoint == feature['endpoint'] ? 10 : 2,
                        shape: RoundedRectangleBorder(
                          borderRadius: BorderRadius.circular(16),
                        ),
                        color: selectedEndpoint == feature['endpoint']
                            ? const Color(0xFF7D98D6)
                            : const Color(0xFFBDC5DA),
                        child: Padding(
                          padding: const EdgeInsets.all(16),
                          child: Column(
                            crossAxisAlignment: CrossAxisAlignment.center,
                            mainAxisAlignment: MainAxisAlignment.center,
                            children: [
                              // Title of the feature
                              Text(
                                feature['title']!,
                                style: TextStyle(
                                  color: selectedEndpoint == feature['endpoint']
                                      ? Colors.white
                                      : const Color(0xFF3B579A),
                                  fontSize: 26,
                                  fontWeight: FontWeight.bold,
                                ),
                                textAlign: TextAlign.center,
                              ),
                              const SizedBox(height: 1),
                              SizedBox(
                                height: 100,
                                width: double.infinity,
                                child: Image.asset(
                                  feature['image'] != null
                                      ? feature['image']!
                                      : 'assets/default_image.png',
                                  height: 50,
                                ),
                              ),
                              const SizedBox(height: 5),
                              Text(
                                feature['description']!,
                                style: TextStyle(
                                  color: selectedEndpoint == feature['endpoint']
                                      ? Colors.white70
                                      : Colors.white,
                                  fontSize: 18,
                                  fontWeight: FontWeight.bold,
                                ),
                                textAlign: TextAlign.center,
                              ),
                            ],
                          ),
                        ),
                      ),
                    ),
                  );
                }
              },
            ),
          ),
          Expanded(
            child: BlocBuilder<ObjectCubit, ObjectPredictionState>(
              builder: (context, state) {
                // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ù…Ù‡ÙŠØ£Ø© ÙˆÙ„Ù… ÙŠØªÙ… Ø§Ù„ØªØ®Ù„Øµ Ù…Ù†Ù‡Ø§
                if (_isCameraInitialized && !_isDisposed && _cameraController.value.isInitialized)
{
                  return Stack(
                    children: [
                      CameraPreview(_cameraController),
                      if (isLoading)
                        const Center(child: CircularProgressIndicator()),
                      if (resultText.isNotEmpty && !isLoading)
                        Positioned(
                          bottom: 20,
                          left: 20,
                          right: 20,
                          child: Container(
                            padding: const EdgeInsets.all(12),
                            decoration: BoxDecoration(
                              color: Colors.black54,
                              borderRadius: BorderRadius.circular(12),
                            ),
                            child: Text(
                              resultText,
                              style: const TextStyle(
                                color: Colors.white,
                                fontSize: 16,
                              ),
                              textAlign: TextAlign.center,
                            ),
                          ),
                        ),
                    ],
                  );
                } else if (state is ObjectLoading) {
                  // Ø­Ø§Ù„Ø© Ø§Ù„ØªØ­Ù…ÙŠÙ„
                  return const Center(child: CircularProgressIndicator());
                } else if (state is ObjectSuccess) {
                  // Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¬Ø§Ø­ Ù…Ø¹ Ø¹Ø±Ø¶ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø³ØªØ®Ù„ØµØ©
                  return _buildPredictionResult(state.prediction);
                } else if (state is ObjectError) {
                  // ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£
                  return Center(
                    child: Text(
                      state.message,
                      style: const TextStyle(color: Colors.red),
                    ),
                  );
                } else {
                  // Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
                  return const Center(
                    child: Text(
                      "Choose Feature to Start",
                      style: TextStyle(
                        color: Color(0xFF3B579A),
                        fontSize: 22,
                        fontWeight: FontWeight.bold,
                      ),
                    ),
                  );
                }
              },
            ),
          )]),
      floatingActionButton: FloatingActionButton(
        onPressed: _startListening,
        backgroundColor: const Color(0xFFBDC5DA),
        child: Icon(
          _isListening ? Icons.mic : Icons.mic_none,
          color: const Color(0xFF3B579A),
          size: 20,
        ),
      ),
    );
  }
  Widget _buildPredictionResult(ObjectPrediction prediction) {
    return Padding(
      padding: const EdgeInsets.all(16.0),
      child: SingleChildScrollView(
        child: Column(
          crossAxisAlignment: CrossAxisAlignment.center,
          children: [
            if (prediction.text != null)
              SelectableText(
                "Extracted Text:\n${prediction.text!}",
                style: const TextStyle(fontSize: 16, fontWeight: FontWeight.bold),
              ),
            if (prediction.description != null)
              Padding(
                padding: const EdgeInsets.only(top: 8.0),
                child: Text("Description: ${prediction.description!}"),
              ),
            if (prediction.alerts != null && prediction.alerts!.isNotEmpty)
              Padding(
                padding: const EdgeInsets.only(top: 8.0),
                child: Column(
                  crossAxisAlignment: CrossAxisAlignment.start,
                  children: prediction.alerts!
                      .map((alert) => Text("Alert: $alert", style: const TextStyle(color: Colors.red)))
                      .toList(),
                ),
              ),
          ],
        ),
      ),
    );
  }
}
===== E:\vision_aid\lib\main.dart =====
import 'package:flutter/material.dart';
import 'package:flutter_bloc/flutter_bloc.dart';

import 'cubit/object_cubit.dart';
import 'splash.dart';

void main() {
  runApp(BlocProvider(create: (context) => ObjectCubit(), child: const MyApp()));
}

class MyApp extends StatelessWidget {
  const MyApp({super.key});

  @override
  Widget build(BuildContext context) {
    return MaterialApp(debugShowCheckedModeBanner: false, home:  Splash());
  }
}


===== E:\vision_aid\lib\object_model.dart =====
class ObjectPrediction {
  final String? description;
  final List<String>? alerts;
  final String? text;

  ObjectPrediction({
    this.description,
    this.alerts,
    this.text,
  });

  factory ObjectPrediction.fromJson(Map<String, dynamic> json) {
    return ObjectPrediction(
      description: json['description'],
      alerts: List<String>.from(json['alerts'] ?? []),
      text: json['text'],
    );
  }
}
===== E:\vision_aid\lib\onboarding.dart =====
import 'package:flutter/material.dart';
import 'package:flutter_tts/flutter_tts.dart';
import 'package:lottie/lottie.dart';
import 'home.dart' show FeatureCardScreen;

class OnboardingScreen extends StatefulWidget {
  const OnboardingScreen({super.key});

  @override
  State<OnboardingScreen> createState() => _OnboardingScreenState();
}

class _OnboardingScreenState extends State<OnboardingScreen> {
  final PageController _pageController = PageController();
  int _currentIndex = 0;
  late FlutterTts _flutterTts;

  final List<Map<String, String>> onboardingData = [
    {
      "image": "assets/recognation.json",
      "title": "WELCOME TO VISION",
      "description": "Your personal visual assistant for daily tasks",
    },
    {
      "image": "assets/search.json",
      "title": "OBJECT RECOGNITION",
      "description": "Hear clear descriptions of objects around you",
    },
    {
      "image": "assets/scan.json",
      "title": "TEXT READING",
      "description": "instant audio feedback from printed text",
    },
  ];

  @override
  void initState() {
    super.initState();
    _flutterTts = FlutterTts();
    _speakCurrentPage();
  }
  Future<void> _speakCurrentPage() async {
    final title = onboardingData[_currentIndex]["title"];
    final desc = onboardingData[_currentIndex]["description"];

    await _flutterTts.setLanguage("en-US");
    await _flutterTts.setSpeechRate(0.5);
    await _flutterTts.setPitch(1.0);
    await _flutterTts.speak("$title. $desc");
  }

  Future<void> _completeOnboarding() async {
    Navigator.pushReplacement(
      context,
      MaterialPageRoute(builder: (context) => FeatureCardScreen()),
    );
  }

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      body: Column(
        children: [
          Expanded(
            child: PageView.builder(
              controller: _pageController,
              itemCount: onboardingData.length,
              onPageChanged: (index) {
                setState(() => _currentIndex = index);
                _speakCurrentPage();

              },
              itemBuilder: (context, index) {
                return OnboardingPage(
                  image: onboardingData[index]["image"]!,
                  title: onboardingData[index]["title"]!,
                  description: onboardingData[index]["description"]!,
                );
              },
            ),
          ),
          Padding(
            padding: const EdgeInsets.symmetric(horizontal: 35, vertical: 20),
            child: Column(
              children: [
                Row(
                  mainAxisAlignment: MainAxisAlignment.center,
                  children: List.generate(onboardingData.length, (index) {
                    return AnimatedContainer(
                      duration: const Duration(milliseconds: 150),
                      margin: const EdgeInsets.symmetric(horizontal: 5),
                      height: 10,
                      width: _currentIndex == index ? 30 : 10,
                      decoration: BoxDecoration(
                        color: _currentIndex == index
                            ? const Color(0xFF4178bf)
                            : const Color(0xff8e9598),
                        borderRadius: BorderRadius.circular(5),
                      ),
                    );
                  }),
                ),
                SizedBox(height: 40,),
                Padding(
                  padding: const EdgeInsets.only(bottom:30.0),
                  child: MaterialButton(
                      onPressed: () {
                        if (_currentIndex < onboardingData.length - 1) {
                          _pageController.nextPage(
                            duration: const Duration(milliseconds: 500),
                            curve: Curves.easeInOut,
                          );
                        } else {
                          _completeOnboarding();
                        }
                      },
                      color: const Color(0xFF4178bf),
                      shape: RoundedRectangleBorder(
                        borderRadius: BorderRadius.circular(20),
                      ),
                      minWidth: 300,
                      height: 60,
                      child: Text(
                        "Next",
                        style: TextStyle(fontSize: 18, color: Colors.white),
                      ),
                    ),
                ),

              ],
            ),
          ),
        ],
      ),
    );
  }
}

class OnboardingPage extends StatelessWidget {
  final String image, title, description;

  const OnboardingPage({
    super.key,
    required this.image,
    required this.title,
    required this.description,
  });

  @override
  Widget build(BuildContext context) {
    return Padding(
      padding: const EdgeInsets.all(16.0),
      child: Column(
        mainAxisAlignment: MainAxisAlignment.center,
        children: [
           Lottie.asset(
             image,
            width: 250,
            height: 250,
            fit: BoxFit.cover,
            repeat: true,
          ),
          const SizedBox(height: 20),
          Align(
            alignment: Alignment.center,
            child: Text(
              title,
              style: const TextStyle(fontSize: 24, fontWeight: FontWeight.bold),
            ),
          ),
          const SizedBox(height: 10),
          Text(
            description,
            style: const TextStyle(fontSize: 16, color: Color(0xFF696969)),
          ),
        ],
      ),
    );
  }
}
===== E:\vision_aid\lib\service.dart =====

import 'dart:async';
import 'dart:convert';
import 'dart:io';
import 'package:http/http.dart' as http;
import 'package:nb_utils/nb_utils.dart';
import 'package:http_parser/http_parser.dart'; // Add for MIME type support
import 'object_model.dart';

class ApiService {
  String? getFileExtension(String filePath) {
    return filePath.split('.').last;
  }

  bool isValidImageFile(File file) {
    List<String> validExtensions = ['jpg', 'jpeg', 'png', 'gif', 'bmp'];
    String? extension = getFileExtension(file.path);
    return extension != null && validExtensions.contains(extension.toLowerCase());
  }

  Future<ObjectPrediction?> fetchDataFromApi(File file, String endpoint) async {
    if (!file.existsSync()) {
      print('Error: File does not exist');
      return null;
    }

    // Validate file type
    if (!isValidImageFile(file)) {
      Fluttertoast.showToast(msg: 'Invalid file type. Please upload an image.');
      return null;
    }

    final Uri url = Uri.parse("http://192.168.100.3:8000/$endpoint");


    try {
      var request = http.MultipartRequest('POST', url)
        ..files.add(await http.MultipartFile.fromPath(
          'file',
          file.path,
          contentType: MediaType('image', getFileExtension(file.path) ?? 'jpeg'), // Set MIME type based on file extension
        ))
        ..headers.addAll({
          'Accept': 'application/json',
        });

      var streamedResponse = await request.send().timeout(Duration(seconds: 60));

      if (streamedResponse.statusCode == 200) {
        final responseBody = await streamedResponse.stream.bytesToString();
        print(responseBody); // or response.body

        if (responseBody.isEmpty) {
          Fluttertoast.showToast(msg: 'Empty response from API');
          return null;
        }

        final jsonData = json.decode(responseBody);
        return ObjectPrediction.fromJson(jsonData);
      } else {
        final responseBody = await streamedResponse.stream.bytesToString();
        return null;
      }
    } catch (e) {
      if (e is SocketException) {
        Fluttertoast.showToast(msg: 'No internet connection');
      } else if (e is TimeoutException) {
        Fluttertoast.showToast(msg: 'Request timed out');
      } else {
        Fluttertoast.showToast(msg: 'Error: $e');
        print('Error: $e');
      }
      return null;
    }
  }
}

===== E:\vision_aid\lib\splash.dart =====
import 'package:flutter/material.dart';
import 'package:flutter_tts/flutter_tts.dart';
import 'onboarding.dart';


class Splash extends StatefulWidget {
  const Splash({super.key});

  @override
  State<Splash> createState() => _SplashState();
}

class _SplashState extends State<Splash> {
  late FlutterTts _flutterTts;

  @override
  void initState() {
    super.initState();

    _flutterTts = FlutterTts();
    _speakWelcomeMessage();

    WidgetsBinding.instance.addPostFrameCallback((_) {
      Future.delayed(const Duration(seconds: 5), () {
        Navigator.of(context).pushReplacement(
          MaterialPageRoute(builder: (context) => OnboardingScreen()),
        );
      });
    });
  }

  Future<void> _speakWelcomeMessage() async {
    await _flutterTts.setLanguage('en-US');
    await _flutterTts.setSpeechRate(0.5);
    await _flutterTts.setPitch(1.0);
    await _flutterTts.speak(
      "Welcome to Smart Vision Features App",
    );
  }

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      body: Center(
        child: Column(
          mainAxisAlignment: MainAxisAlignment.center,
          mainAxisSize: MainAxisSize.min,
          children: [
            ClipRRect(
              child: Image.asset(
                'assets/eye.png',
                width: 220,
                height: 220,
                fit: BoxFit.fill,
              ),
            ),
          ],
        ),
      ),
    );
  }
}
